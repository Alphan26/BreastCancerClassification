{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbG69QSD28qR"
   },
   "source": [
    "# Finding the MRI brain tumor detection dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcMFxKfv28qS"
   },
   "source": [
    "Let's find the dataset in this link: https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wsrtTwy28qS"
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn opencv-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch==2.0+cu117 --user -f https://download.pytorch.org/whl/cu117/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchvision==0.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "yAZXXlHp28qS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import glob\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import random\n",
    "import cv2\n",
    "import sys\n",
    "from torchvision import models,transforms,datasets\n",
    "import time\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.folder import default_loader\n",
    "import torchvision\n",
    "from sklearn .metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hJtcehDm4H4Z",
    "outputId": "64b5758f-3074-4d9a-9f75-50ffc024f9d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA RTX A4000'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.is_available()) # this should return true\n",
    "torch.cuda.get_device_name() # this should return your graphics card name. Ex) 'NVIDIA RTX A4000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "hV1jmdLT5LKF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom zipfile import ZipFile \\n\\n # loading the temp.zip and creating a zip object \\nwith ZipFile(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis_ddsm.zip\", \\'r\\') as zObject: \\n    zObject.extractall() \\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # importing the zipfile module \n",
    "\"\"\"\n",
    "from zipfile import ZipFile \n",
    "\n",
    " # loading the temp.zip and creating a zip object \n",
    "with ZipFile(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis_ddsm.zip\", 'r') as zObject: \n",
    "    zObject.extractall() \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.248386...\n",
       "2     CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.267213...\n",
       "11    CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.210396...\n",
       "12    CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.749566...\n",
       "15    CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.987658...\n",
       "Name: image_path, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dicom_data = pd.read_csv(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\dicom_info.csv\")\n",
    "\n",
    "full_mammogram_images = dicom_data[dicom_data.SeriesDescription == 'full mammogram images'].image_path\n",
    "full_mammogram_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ae423\\AppData\\Local\\Temp\\ipykernel_21928\\1692899711.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  mass_train.iloc[0][11].split(\"/\")[2]\n"
     ]
    }
   ],
   "source": [
    "# load the mass dataset\n",
    "mass_train = pd.read_csv('C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\mass_case_description_train_set.csv')\n",
    "mass_test = pd.read_csv('C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\mass_case_description_test_set.csv')\n",
    "\n",
    "#mass_train.head()\n",
    "mass_train.iloc[0][11].split(\"/\")[2]\n",
    "\n",
    "# fix image paths\n",
    "def fix_image_path(data):\n",
    " #   \"\"\"correct dicom paths to correct image paths\"\"\"\n",
    "  for index, img in enumerate(data.values):\n",
    "    img_name = img[11].split(\"/\")[2]\n",
    "    new_path = \"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\jpeg\\\\\" + img_name\n",
    "    data.iloc[index,11] = new_path\n",
    "      \n",
    "# apply to datasets\n",
    "fix_image_path(mass_train)\n",
    "fix_image_path(mass_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_train = pd.read_csv('C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\calc_case_description_train_set.csv')\n",
    "calc_test = pd.read_csv('C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\calc_case_description_test_set.csv')\n",
    "\n",
    "fix_image_path(calc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544\n",
      "1546\n"
     ]
    }
   ],
   "source": [
    "temp_calc_train = calc_train[[\"image file path\",\"pathology\"]]\n",
    "calc_normal = []\n",
    "calc_malignant = []\n",
    "for row,col in temp_calc_train.iterrows():\n",
    "    if col[\"pathology\"] == \"MALIGNANT\":\n",
    "        calc_malignant.append(col[\"image file path\"])\n",
    "    else:\n",
    "        calc_normal.append(col[\"image file path\"])\n",
    "\n",
    "print(len(calc_normal))\n",
    "print(len(calc_malignant))\n",
    "print(len(temp_calc_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681\n",
      "637\n",
      "1318\n"
     ]
    }
   ],
   "source": [
    "new_df = mass_train[[\"image file path\",\"pathology\"]]\n",
    "new_df\n",
    "\n",
    "normal_path = []\n",
    "malignant_path = []\n",
    "for row,col in new_df.iterrows():\n",
    "    if col[\"pathology\"] == \"MALIGNANT\":\n",
    "        # put this file to the malignant folder\n",
    "        malignant_path.append(col[\"image file path\"])\n",
    "    else:\n",
    "        normal_path.append(col[\"image file path\"])\n",
    "\n",
    "print(len(normal_path))\n",
    "print(len(malignant_path))\n",
    "print(len(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2319\n",
      "258\n",
      "287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "last_df = pd.concat([temp_calc_train,new_df])\n",
    "temp,test = train_test_split(last_df, test_size=0.1,shuffle= True)\n",
    "train,val = train_test_split(temp, test_size=0.1,shuffle= True)\n",
    "\n",
    "print(len(train))\n",
    "print(len(val))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shutil\n",
    "\n",
    "def write_into_train_folder():\n",
    "    for row,col in train.iterrows():\n",
    "        for img_name in os.listdir(col[\"image file path\"]):\n",
    "            img_path = col[\"image file path\"] + \"\\\\\" + img_name\n",
    "            if col[\"pathology\"] == \"MALIGNANT\":\n",
    "                # put this file to the malignant folder\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-train\\\\malignant\")\n",
    "            else:\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-train\\\\normal\")\n",
    "                # put it into normal folder\n",
    "\n",
    "\n",
    "def write_into_val_folder():\n",
    "    for row,col in val.iterrows():\n",
    "        for img_name in os.listdir(col[\"image file path\"]):\n",
    "            img_path = col[\"image file path\"] + \"\\\\\" + img_name\n",
    "            if col[\"pathology\"] == \"MALIGNANT\":\n",
    "                # put this file to the malignant folder\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-val\\\\malignant\")\n",
    "            else:\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-val\\\\normal\")\n",
    "                # put it into normal folder\n",
    "\n",
    "\n",
    "def write_into_test_folder():\n",
    "    for row,col in test.iterrows():\n",
    "        for img_name in os.listdir(col[\"image file path\"]):\n",
    "            img_path = col[\"image file path\"] + \"\\\\\" + img_name\n",
    "            if col[\"pathology\"] == \"MALIGNANT\":\n",
    "                # put this file to the malignant folder\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-test\\\\malignant\")\n",
    "            else:\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-test\\\\normal\")\n",
    "                # put it into normal folder\n",
    "\n",
    "write_into_train_folder()\n",
    "write_into_val_folder()\n",
    "write_into_test_folder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os \\n#os.makedirs(\"cbis-train/normal\")\\nos.makedirs(\"cbis-train/malignant\")\\nos.makedirs(\"cbis-val/normal\")\\nos.makedirs(\"cbis-val/malignant\")\\nos.makedirs(\"cbis-test/normal\")\\nos.makedirs(\"cbis-test/malignant\")\\n\\ndef write_inside_folder(df):\\n    for folder in df:\\n        for file in os.listdir(folder):\\n            cv2.imwrite(folder,file)\\n\\n#write_inside_folder(train)\\n#write_inside_folder(val)\\n#write_inside_folder(test)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import os \n",
    "#os.makedirs(\"cbis-train/normal\")\n",
    "os.makedirs(\"cbis-train/malignant\")\n",
    "os.makedirs(\"cbis-val/normal\")\n",
    "os.makedirs(\"cbis-val/malignant\")\n",
    "os.makedirs(\"cbis-test/normal\")\n",
    "os.makedirs(\"cbis-test/malignant\")\n",
    "\n",
    "def write_inside_folder(df):\n",
    "    for folder in df:\n",
    "        for file in os.listdir(folder):\n",
    "            cv2.imwrite(folder,file)\n",
    "\n",
    "#write_inside_folder(train)\n",
    "#write_inside_folder(val)\n",
    "#write_inside_folder(test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: alphanhilal (alphanhilal-university-of-sussex). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ae423\\OneDrive - University of Sussex\\Desktop\\AlphanElmasDissertation\\wandb\\run-20240819_220350-r3z4ltdm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim/runs/r3z4ltdm' target=\"_blank\">stoic-pond-1</a></strong> to <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim/runs/r3z4ltdm' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim/runs/r3z4ltdm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"tezim\",\n",
    "    # Track hyperparameters and run metadata\n",
    ")\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCDataset(datasets.ImageFolder):\n",
    "  def __init__(self, root, loader=default_loader, is_valid_file=None):\n",
    "    super(BCDataset, self).__init__(root=root, loader=loader, is_valid_file=is_valid_file)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    \n",
    "    \n",
    "    im = cv2.imread(image_path)\n",
    "    imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    new_img = clahe.apply(imgray)\n",
    "    sample = torchvision.transforms.ToTensor()(new_img)\n",
    "    return sample, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(batch_size):\n",
    "   \n",
    "    transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   #must same as here\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(), # data augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalization\n",
    "])\n",
    "    \n",
    "    train_dir = 'C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-train'\n",
    "    #data = BCDataset(train_dir,transforms_train)\n",
    "    train_dataset = datasets.ImageFolder(train_dir, transforms_train)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    test_dir = 'C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-test'\n",
    "    #data_test = BCDataset(test_dir,transforms_train)\n",
    "    test_dataset = datasets.ImageFolder(test_dir, transforms_train)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    val_dir = 'C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-val'\n",
    "    #data_val = BCDataset(val_dir,transforms_train)\n",
    "    val_dataset = datasets.ImageFolder(val_dir, transforms_train)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    return train_dataloader,test_dataloader,val_dataloader\n",
    "\n",
    "\n",
    "def build_resnet():\n",
    "    model_ft = models.resnet50(weights='IMAGENET1K_V1')\n",
    "    for param in model_ft.parameters():\n",
    "        param.requires_grad = False\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    return model_ft.to(device)\n",
    "\n",
    "def build_densenet():\n",
    "    model_ft = models.densenet169(weights='IMAGENET1K_V1')\n",
    "    for param in model_ft.parameters():\n",
    "        param.requires_grad = False\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    return model_ft.to(device)\n",
    "\n",
    "def build_vggnet():\n",
    "    model_ft = models.vgg19(weights='IMAGENET1K_V1')\n",
    "    for param in model_ft.parameters():\n",
    "        param.requires_grad = False\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    return model_ft.to(device)\n",
    "\n",
    "\n",
    "def build_inception():\n",
    "    model = models.inception_v3(pretrained=True)\n",
    "    model.aux_logits = False\n",
    "\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, 10),\n",
    "    nn.Linear(10, 2)\n",
    "    )\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "def inception_dataset(batch_size):\n",
    "    train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(299),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), # ToTensor : [0, 255] -> [0, 1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "    \n",
    "    train_dir = 'C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-train'\n",
    "    train_dataset = datasets.ImageFolder(train_dir, train_transform)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    test_dir = 'C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-test'\n",
    "    test_dataset = datasets.ImageFolder(test_dir, train_transform)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    val_dir = 'C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-val'\n",
    "    val_dataset = datasets.ImageFolder(val_dir, train_transform)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    return train_dataloader,test_dataloader,val_dataloader\n",
    "        \n",
    "\n",
    "def build_optimizer(network, optimizer, learning_rate):\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(network.parameters(),\n",
    "                              lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(network.parameters(),\n",
    "                               lr=learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def train_epoch(network, loader, optimizer):\n",
    "    cumu_loss = 0\n",
    "    for _, (data, target) in enumerate(loader):\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # ➡ Forward pass\n",
    "        loss = nn.CrossEntropyLoss()(network(data), target)\n",
    "        cumu_loss += loss.item()\n",
    "\n",
    "        # ⬅ Backward pass + weight update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        wandb.log({\"batch loss\": loss.item()})\n",
    "\n",
    "    return cumu_loss / len(loader),\n",
    "\n",
    "\n",
    "\n",
    "def train(config=None):\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "\n",
    "        train_dataloader,test_dataloader,val_dataloader = build_dataset(config.batch_size)\n",
    "        network = build_resnet()\n",
    "        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            avg_loss = train_epoch(network, train_dataloader, optimizer)\n",
    "            wandb.log({\"loss\": avg_loss, \"epoch\": epoch})           \n",
    "\n",
    "\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    train_dataloader,test_dataloader,val_dataloader = build_dataset(32)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        \n",
    "\n",
    "    # Convert lists to tensors for calculation\n",
    "    y_true_tensor = torch.tensor(y_true)\n",
    "    y_pred_tensor = torch.tensor(y_pred)\n",
    "\n",
    "    # Calculating precision, recall, and F1 score using PyTorch\n",
    "    TP = ((y_pred_tensor == 1) & (y_true_tensor == 1)).sum().item()\n",
    "    FP = ((y_pred_tensor == 1) & (y_true_tensor == 0)).sum().item()\n",
    "    FN = ((y_pred_tensor == 0) & (y_true_tensor == 1)).sum().item()\n",
    "\n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    auc = np.round(roc_auc_score(y_true, y_pred), 3)\n",
    "\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    \n",
    "    wandb.log({\"precision\":precision})\n",
    "    wandb.log({\"recall\":recall})\n",
    "    wandb.log({\"f1 score\":f1 score})\n",
    "    wandb.log({\"AUC\":auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'grid',\n",
      " 'metric': {'goal': 'minimize', 'name': 'loss'},\n",
      " 'parameters': {'batch_size': {'values': [32, 64, 128, 256]},\n",
      "                'epochs': {'values': [10, 20]},\n",
      "                'learning_rate': {'values': [0.001, 0.0001]},\n",
      "                'optimizer': {'values': ['adam', 'sgd']}}}\n",
      "Create sweep with ID: icgpo079\n",
      "Sweep URL: https://wandb.ai/alphanhilal-university-of-sussex/tezim/sweeps/icgpo079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Calling wandb.login() after wandb.init() has no effect.\n",
      "wandb: Agent Starting Run: mtsld2ra with config:\n",
      "wandb: \tbatch_size: 32\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tlearning_rate: 0.001\n",
      "wandb: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ae423\\OneDrive - University of Sussex\\Desktop\\AlphanElmasDissertation\\wandb\\run-20240819_220434-mtsld2ra</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim/runs/mtsld2ra' target=\"_blank\">swift-sweep-1</a></strong> to <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim/sweeps/icgpo079' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim/sweeps/icgpo079</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim/sweeps/icgpo079' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim/sweeps/icgpo079</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim/runs/mtsld2ra' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim/runs/mtsld2ra</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread ChkStopThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 303, in check_stop_status\n",
      "    self._loop_check_status(\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 233, in _loop_check_status\n",
      "    local_handle = request()\n",
      "                   ^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 907, in deliver_stop_status\n",
      "    return self._deliver_stop_status(status)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 487, in _deliver_stop_status\n",
      "    return self._deliver_record(record)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 452, in _deliver_record\n",
      "    handle = mailbox._deliver_record(record, interface=self)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py\", line 455, in _deliver_record\n",
      "    interface._publish(record)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36a659c42f241fc8b1ecb8f4b874e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.007 MB uploaded\\r'), FloatProgress(value=0.1533134166214014, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▇█▅▃▄▃▂▂▂▂▂▂▂▂▂▄▂▃▂▃▂▁▂▂▃▂▂▂▁▂▁▂▃▃▂▁▂▁▂▁</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▄▂▂▂▂▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.61021</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.67455</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swift-sweep-1</strong> at: <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim/runs/mtsld2ra' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim/runs/mtsld2ra</a><br/> View project at: <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240819_220434-mtsld2ra\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: eovdv659 with config:\n",
      "wandb: \tbatch_size: 32\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tlearning_rate: 0.001\n",
      "wandb: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ae423\\OneDrive - University of Sussex\\Desktop\\AlphanElmasDissertation\\wandb\\run-20240819_221102-eovdv659</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim/runs/eovdv659' target=\"_blank\">drawn-sweep-2</a></strong> to <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim/sweeps/icgpo079' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim/sweeps/icgpo079</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim/sweeps/icgpo079' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim/sweeps/icgpo079</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim/runs/eovdv659' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim/runs/eovdv659</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429ac5ace3ab40c19456d5308306493a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▆▇▅▅▄▆█▅▆▅▆▆▄▇▅▂▇█▃▄▄▄▄▄▅▄▂▁▃▇▆▃▅▂▅▃▆▆▆▆</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▇█▅▅▃▄▄▁▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.7062</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.69234</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">drawn-sweep-2</strong> at: <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim/runs/eovdv659' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim/runs/eovdv659</a><br/> View project at: <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240819_221102-eovdv659\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: xaguwnak with config:\n",
      "wandb: \tbatch_size: 32\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tlearning_rate: 0.0001\n",
      "wandb: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ae423\\OneDrive - University of Sussex\\Desktop\\AlphanElmasDissertation\\wandb\\run-20240819_221730-xaguwnak</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim/runs/xaguwnak' target=\"_blank\">distinctive-sweep-3</a></strong> to <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim/sweeps/icgpo079' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim/sweeps/icgpo079</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim/sweeps/icgpo079' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim/sweeps/icgpo079</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanhilal-university-of-sussex/tezim/runs/xaguwnak' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/tezim/runs/xaguwnak</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid'\n",
    "    }\n",
    "\n",
    "metric = {\n",
    "    'name': 'loss',\n",
    "    'goal': 'minimize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "parameters_dict = {\n",
    "    'optimizer': {\n",
    "        'values': ['adam', 'sgd']\n",
    "        },\n",
    "    'learning_rate': {\n",
    "        \"values\" : [0.001, 0.0001]\n",
    "      },\n",
    "      'batch_size': {\n",
    "        \"values\" : [32,64,128,256]\n",
    "      },\n",
    "      \"epochs\" : {\n",
    "        \"values\" : [10,20]\n",
    "      }\n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(sweep_config)\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"tezim\")\n",
    "\n",
    "wandb.agent(sweep_id, train, count=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x00000236D8BDE710>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 236ddeab990, raw_cell=\"#model_ft = train_model(model_ft, criterion, optim..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/ae423/OneDrive%20-%20University%20of%20Sussex/Desktop/AlphanElmasDissertation/Alphan_Elmas_Dissertation%20%281%29%20%281%29.ipynb#X42sZmlsZQ%3D%3D>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:441\u001b[0m, in \u001b[0;36m_WandbInit._resume_backend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    440\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mpublish_resume()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\interface\\interface.py:732\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n\u001b[1;32m--> 732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish_resume(resume)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py:363\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[1;34m(self, resume)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    362\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish(rec)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[1;34m(self, record, local)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock_client\u001b[38;5;241m.\u001b[39msend_record_publish(record)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[0;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend_server_request(server_req)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_message(msg)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sendall_with_error_handle(header \u001b[38;5;241m+\u001b[39m data)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msend(data)\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x00000236D8BDE710>> (for post_run_cell), with arguments args (<ExecutionResult object at 236ddf9efd0, execution_count=29 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 236ddeab990, raw_cell=\"#model_ft = train_model(model_ft, criterion, optim..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/ae423/OneDrive%20-%20University%20of%20Sussex/Desktop/AlphanElmasDissertation/Alphan_Elmas_Dissertation%20%281%29%20%281%29.ipynb#X42sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:436\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    435\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m--> 436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mpublish_pause()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\interface\\interface.py:724\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    723\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[1;32m--> 724\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish_pause(pause)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py:359\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[1;34m(self, pause)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[1;32m--> 359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish(rec)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[1;34m(self, record, local)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock_client\u001b[38;5;241m.\u001b[39msend_record_publish(record)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[0;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend_server_request(server_req)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_message(msg)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sendall_with_error_handle(header \u001b[38;5;241m+\u001b[39m data)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msend(data)\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    }
   ],
   "source": [
    "#model_ft = train_model(model_ft, criterion, optimizer_ft,num_epochs=3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
