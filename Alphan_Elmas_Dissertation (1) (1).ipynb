{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbG69QSD28qR"
   },
   "source": [
    "# Breast Cancer Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wsrtTwy28qS"
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn opencv-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch==2.0+cu117 --user -f https://download.pytorch.org/whl/cu117/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchvision==0.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yAZXXlHp28qS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import glob\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import random\n",
    "import cv2\n",
    "import sys\n",
    "from torchvision import models,transforms,datasets\n",
    "import time\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.folder import default_loader\n",
    "import torchvision\n",
    "from sklearn .metrics import roc_auc_score,accuracy_score,precision_score,recall_score,f1_score\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hJtcehDm4H4Z",
    "outputId": "64b5758f-3074-4d9a-9f75-50ffc024f9d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA RTX A4000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.is_available()) # this should return true\n",
    "torch.cuda.get_device_name() # this should return your graphics card name. Ex) 'NVIDIA RTX A4000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hV1jmdLT5LKF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom zipfile import ZipFile \\n\\n # loading the temp.zip and creating a zip object \\nwith ZipFile(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis_ddsm.zip\", \\'r\\') as zObject: \\n    zObject.extractall() \\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # importing the zipfile module \n",
    "\"\"\"\n",
    "from zipfile import ZipFile \n",
    "\n",
    " # loading the temp.zip and creating a zip object \n",
    "with ZipFile(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis_ddsm.zip\", 'r') as zObject: \n",
    "    zObject.extractall() \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.248386...\n",
       "2     CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.267213...\n",
       "11    CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.210396...\n",
       "12    CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.749566...\n",
       "15    CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.987658...\n",
       "Name: image_path, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dicom_data = pd.read_csv(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\dicom_info.csv\")\n",
    "\n",
    "full_mammogram_images = dicom_data[dicom_data.SeriesDescription == 'full mammogram images'].image_path\n",
    "full_mammogram_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ae423\\AppData\\Local\\Temp\\ipykernel_23504\\2910366824.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  mass_train.iloc[0][11].split(\"/\")[2]\n"
     ]
    }
   ],
   "source": [
    "# load the mass dataset\n",
    "mass_train = pd.read_csv('C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\mass_case_description_train_set.csv')\n",
    "mass_test = pd.read_csv('C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\mass_case_description_test_set.csv')\n",
    "\n",
    "#mass_train.head()\n",
    "mass_train.iloc[0][11].split(\"/\")[2]\n",
    "\n",
    "# fix image paths\n",
    "def fix_image_path(data):\n",
    " #   correct dicom paths to correct image paths\n",
    "  for index, img in enumerate(data.values):\n",
    "    img_name = img[11].split(\"/\")[2]\n",
    "    new_path = \"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\jpeg\\\\\" + img_name\n",
    "    data.iloc[index,11] = new_path\n",
    "      \n",
    "# apply to datasets\n",
    "fix_image_path(mass_train)\n",
    "fix_image_path(mass_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "calc_train = pd.read_csv('C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\calc_case_description_train_set.csv')\n",
    "calc_test = pd.read_csv('C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\calc_case_description_test_set.csv')\n",
    "\n",
    "fix_image_path(calc_train)\n",
    "fix_image_path(calc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002\n",
      "544\n",
      "1546\n"
     ]
    }
   ],
   "source": [
    "temp_calc_train = calc_train[[\"image file path\",\"pathology\"]]\n",
    "calc_normal = []\n",
    "calc_malignant = []\n",
    "for row,col in temp_calc_train.iterrows():\n",
    "    if col[\"pathology\"] == \"MALIGNANT\":\n",
    "        calc_malignant.append(col[\"image file path\"])\n",
    "    else:\n",
    "        calc_normal.append(col[\"image file path\"])\n",
    "\n",
    "print(len(calc_normal))\n",
    "print(len(calc_malignant))\n",
    "print(len(temp_calc_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681\n",
      "637\n",
      "1318\n"
     ]
    }
   ],
   "source": [
    "new_df = mass_train[[\"image file path\",\"pathology\"]]\n",
    "\n",
    "normal_path = []\n",
    "malignant_path = []\n",
    "for row,col in new_df.iterrows():\n",
    "    if col[\"pathology\"] == \"MALIGNANT\":\n",
    "        # put this file to the malignant folder\n",
    "        malignant_path.append(col[\"image file path\"])\n",
    "    else:\n",
    "        normal_path.append(col[\"image file path\"])\n",
    "\n",
    "print(len(normal_path))\n",
    "print(len(malignant_path))\n",
    "print(len(new_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "128\n",
      "295\n",
      "296\n",
      "86\n",
      "125\n"
     ]
    }
   ],
   "source": [
    "path = \"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\\"\n",
    "print(len(os.listdir(os.path.join(path,\"cbis-test\\\\malignant\"))))\n",
    "print(len(os.listdir(os.path.join(path,\"cbis-test\\\\normal\"))))\n",
    "print(len(os.listdir(os.path.join(path,\"cbis-train\\\\malignant\"))))\n",
    "print(len(os.listdir(os.path.join(path,\"cbis-train\\\\normal\"))))\n",
    "print(len(os.listdir(os.path.join(path,\"cbis-val\\\\malignant\"))))\n",
    "print(len(os.listdir(os.path.join(path,\"cbis-val\\\\normal\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image file path</th>\n",
       "      <th>pathology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>BENIGN_WITHOUT_CALLBACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>BENIGN_WITHOUT_CALLBACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>BENIGN_WITHOUT_CALLBACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>BENIGN_WITHOUT_CALLBACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>MALIGNANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>MALIGNANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>MALIGNANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>MALIGNANT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>704 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image file path  \\\n",
       "0    C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "1    C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "2    C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "3    C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "4    C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "..                                                 ...   \n",
       "373  C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "374  C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "375  C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "376  C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "377  C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "\n",
       "                   pathology  \n",
       "0                     BENIGN  \n",
       "1                     BENIGN  \n",
       "2    BENIGN_WITHOUT_CALLBACK  \n",
       "3    BENIGN_WITHOUT_CALLBACK  \n",
       "4    BENIGN_WITHOUT_CALLBACK  \n",
       "..                       ...  \n",
       "373  BENIGN_WITHOUT_CALLBACK  \n",
       "374                MALIGNANT  \n",
       "375                MALIGNANT  \n",
       "376                MALIGNANT  \n",
       "377                MALIGNANT  \n",
       "\n",
       "[704 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "temp,test = train_test_split(last_df, test_size=0.1,shuffle= True)\n",
    "train,val = train_test_split(temp, test_size=0.1,shuffle= True)\n",
    "\n",
    "print(len(train))\n",
    "print(len(val))\n",
    "print(len(test))\n",
    "\"\"\"\n",
    "last_df = pd.concat([temp_calc_train,new_df])\n",
    "calc_test = calc_test[[\"image file path\",\"pathology\"]]\n",
    "mass_test = mass_test[[\"image file path\",\"pathology\"]]\n",
    "new_test = pd.concat([calc_test,mass_test])\n",
    "\n",
    "train = last_df[:2160]\n",
    "val = last_df[2160:]\n",
    "test = new_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport shutil\\n\\ndef write_into_train_folder():\\n    for row,col in train.iterrows():\\n        for img_name in os.listdir(col[\"image file path\"]):\\n            img_path = col[\"image file path\"] + \"\\\\\" + img_name\\n            if col[\"pathology\"] == \"MALIGNANT\":\\n                # put this file to the malignant folder\\n                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-train\\\\malignant\")\\n            else:\\n                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-train\\\\normal\")\\n                # put it into normal folder\\n\\n\\ndef write_into_val_folder():\\n    for row,col in val.iterrows():\\n        for img_name in os.listdir(col[\"image file path\"]):\\n            img_path = col[\"image file path\"] + \"\\\\\" + img_name\\n            if col[\"pathology\"] == \"MALIGNANT\":\\n                # put this file to the malignant folder\\n                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-val\\\\malignant\")\\n            else:\\n                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-val\\\\normal\")\\n                # put it into normal folder\\n\\n\\ndef write_into_test_folder():\\n    for row,col in test.iterrows():\\n        for img_name in os.listdir(col[\"image file path\"]):\\n            img_path = col[\"image file path\"] + \"\\\\\" + img_name\\n            if col[\"pathology\"] == \"MALIGNANT\":\\n                # put this file to the malignant folder\\n                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-test\\\\malignant\")\\n            else:\\n                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-test\\\\normal\")\\n                # put it into normal folder\\n\\nwrite_into_train_folder()\\nwrite_into_val_folder()\\nwrite_into_test_folder()\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import shutil\n",
    "\n",
    "def write_into_train_folder():\n",
    "    for row,col in train.iterrows():\n",
    "        for img_name in os.listdir(col[\"image file path\"]):\n",
    "            img_path = col[\"image file path\"] + \"\\\\\" + img_name\n",
    "            if col[\"pathology\"] == \"MALIGNANT\":\n",
    "                # put this file to the malignant folder\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-train\\\\malignant\")\n",
    "            else:\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-train\\\\normal\")\n",
    "                # put it into normal folder\n",
    "\n",
    "\n",
    "def write_into_val_folder():\n",
    "    for row,col in val.iterrows():\n",
    "        for img_name in os.listdir(col[\"image file path\"]):\n",
    "            img_path = col[\"image file path\"] + \"\\\\\" + img_name\n",
    "            if col[\"pathology\"] == \"MALIGNANT\":\n",
    "                # put this file to the malignant folder\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-val\\\\malignant\")\n",
    "            else:\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-val\\\\normal\")\n",
    "                # put it into normal folder\n",
    "\n",
    "\n",
    "def write_into_test_folder():\n",
    "    for row,col in test.iterrows():\n",
    "        for img_name in os.listdir(col[\"image file path\"]):\n",
    "            img_path = col[\"image file path\"] + \"\\\\\" + img_name\n",
    "            if col[\"pathology\"] == \"MALIGNANT\":\n",
    "                # put this file to the malignant folder\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-test\\\\malignant\")\n",
    "            else:\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-test\\\\normal\")\n",
    "                # put it into normal folder\n",
    "\n",
    "write_into_train_folder()\n",
    "write_into_val_folder()\n",
    "write_into_test_folder()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os \\n#os.makedirs(\"cbis-train/normal\")\\nos.makedirs(\"cbis-train/malignant\")\\nos.makedirs(\"cbis-val/normal\")\\nos.makedirs(\"cbis-val/malignant\")\\nos.makedirs(\"cbis-test/normal\")\\nos.makedirs(\"cbis-test/malignant\")\\n\\ndef write_inside_folder(df):\\n    for folder in df:\\n        for file in os.listdir(folder):\\n            cv2.imwrite(folder,file)\\n\\n#write_inside_folder(train)\\n#write_inside_folder(val)\\n#write_inside_folder(test)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import os \n",
    "#os.makedirs(\"cbis-train/normal\")\n",
    "os.makedirs(\"cbis-train/malignant\")\n",
    "os.makedirs(\"cbis-val/normal\")\n",
    "os.makedirs(\"cbis-val/malignant\")\n",
    "os.makedirs(\"cbis-test/normal\")\n",
    "os.makedirs(\"cbis-test/malignant\")\n",
    "\n",
    "def write_inside_folder(df):\n",
    "    for folder in df:\n",
    "        for file in os.listdir(folder):\n",
    "            cv2.imwrite(folder,file)\n",
    "\n",
    "#write_inside_folder(train)\n",
    "#write_inside_folder(val)\n",
    "#write_inside_folder(test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: alphanhilal (alphanhilal-university-of-sussex). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ae423\\OneDrive - University of Sussex\\Desktop\\AlphanElmasDissertation\\wandb\\run-20240823_144101-7q9wku74</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanhilal-university-of-sussex/Resnet50%20Output/runs/7q9wku74' target=\"_blank\">laced-snowball-21</a></strong> to <a href='https://wandb.ai/alphanhilal-university-of-sussex/Resnet50%20Output' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanhilal-university-of-sussex/Resnet50%20Output' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/Resnet50%20Output</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanhilal-university-of-sussex/Resnet50%20Output/runs/7q9wku74' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/Resnet50%20Output/runs/7q9wku74</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"Resnet50 Output\",\n",
    "    # Track hyperparameters and run metadata\n",
    ")\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLAHE():\n",
    "    \n",
    "    def __init__(self, clipLimit=2.0, tileGridSize=(16,16)):\n",
    "        super().__init__\n",
    "        self.clipLimit = clipLimit\n",
    "        self.tileGridSize = tileGridSize\n",
    "\n",
    "    def __call__(self,sample):\n",
    "      img = np.array(sample)\n",
    "      img = np.moveaxis(img,0,2)\n",
    "      imgray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "      imgray = imgray.astype(np.uint16)\n",
    "      clahe = cv2.createCLAHE(clipLimit=self.clipLimit, tileGridSize=self.tileGridSize)\n",
    "      new_img = clahe.apply(imgray)\n",
    "      new_img = cv2.cvtColor(new_img, cv2.COLOR_GRAY2BGR)\n",
    "      new_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB)\n",
    "      new_img = new_img.astype(np.float32)\n",
    "      new_img = np.moveaxis(new_img,2,0)\n",
    "      tensor = torch.tensor(new_img)\n",
    "      #print(img.shape)\n",
    "      return tensor\n",
    "\n",
    "\n",
    "class GaussianNoise():\n",
    "\n",
    "    def __init__(self,mean=0,stddev=0.01):\n",
    "        super().__init__\n",
    "        self.mean = mean\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def __call__(self,sample):\n",
    "        sample = sample.cpu()\n",
    "        input_array = sample.data.numpy()\n",
    "\n",
    "        noise = np.random.normal(loc=self.mean, scale=self.stddev, size=np.shape(input_array))\n",
    "\n",
    "        out = np.add(input_array, noise)\n",
    "\n",
    "        output_tensor = torch.from_numpy(out)\n",
    "        out_tensor = Variable(output_tensor)\n",
    "        out = out_tensor.cuda()\n",
    "        out = out.float()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_model = None\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.status = \"\"\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "        elif self.best_loss - val_loss >= self.min_delta:\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.status = f\"Improvement found, counter reset to {self.counter}\"\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            self.status = f\"No improvement in the last {self.counter} epochs\"\n",
    "            if self.counter >= self.patience:\n",
    "                self.status = f\"Early stopping triggered after {self.counter} epochs.\"\n",
    "                if self.restore_best_weights:\n",
    "                    model.load_state_dict(self.best_model)\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_predictions = [] # The outputs of predictions will be stored in this array\n",
    "numerical_predictions = [] # Numerical predictions will be stored in this array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "Best epoch 2\n",
      "464\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "2048\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(batch_size):\n",
    "   \n",
    "    transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # data augmentation\n",
    "    transforms.RandomRotation(degrees=(0,180)),\n",
    "    transforms.RandomAffine(degrees = 0, translate = (0.2, 0.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), # normalization\n",
    "    CLAHE(),\n",
    "    GaussianNoise()\n",
    "\n",
    "])\n",
    "    \n",
    "    train_dir = 'C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-train'\n",
    "    train_dataset = datasets.ImageFolder(train_dir, transforms_train)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    test_dir = 'C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-test'\n",
    "    test_dataset = datasets.ImageFolder(test_dir, transforms_train)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    val_dir = 'C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-val'\n",
    "    val_dataset = datasets.ImageFolder(val_dir, transforms_train)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    return train_dataloader,test_dataloader,val_dataloader\n",
    "\n",
    "\n",
    "def build_resnet():\n",
    "    model_ft = models.resnet50(weights='IMAGENET1K_V1')\n",
    "    for param in model_ft.parameters():\n",
    "        param.requires_grad = False\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    print(num_ftrs)\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    return model_ft.to(device)\n",
    "\n",
    "def build_densenet():\n",
    "    model_ft = models.densenet169(weights='IMAGENET1K_V1')\n",
    "    for param in model_ft.parameters():\n",
    "        param.requires_grad = False\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    return model_ft.to(device)\n",
    "\n",
    "        \n",
    "\n",
    "def build_optimizer(network, optimizer, learning_rate):\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(network.parameters(),\n",
    "                              lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(network.parameters(),\n",
    "                               lr=learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def train_epoch(network, loader, optimizer):\n",
    "    cumu_loss = 0\n",
    "    for _, (data, target) in enumerate(loader): # batch batch butun datayi gezip loss degerlerini hesapliyorum\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # ➡ Forward pass\n",
    "        loss = nn.CrossEntropyLoss()(network(data), target)\n",
    "        cumu_loss += loss.item()\n",
    "\n",
    "        # ⬅ Backward pass + weight update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    return cumu_loss / len(loader)\n",
    "\n",
    "\n",
    "\n",
    "def train(config=None):\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        train_dataloader,test_dataloader,val_dataloader = build_dataset(config.batch_size)\n",
    "        network = build_resnet()\n",
    "        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)\n",
    "        scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.5, total_iters=10)\n",
    "        es = EarlyStopping()\n",
    "        best_val_loss = np.inf\n",
    "        PATH = './cifar_net.pth'\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            network.train(True)\n",
    "            avg_loss = train_epoch(network, train_dataloader, optimizer)\n",
    "            scheduler.step()\n",
    "            wandb.log({\"training_loss\": avg_loss, \"epoch\": epoch})    \n",
    "            running_vloss = 0\n",
    "            network.eval()\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            with torch.no_grad():\n",
    "                for i, vdata in enumerate(val_dataloader):\n",
    "                    vinputs, vlabels = vdata\n",
    "                    vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "                    voutputs = network(vinputs)\n",
    "                    vloss = loss_fn(voutputs, vlabels)\n",
    "                    running_vloss += vloss     \n",
    "\n",
    "                avg_valloss = running_vloss / (i + 1) # avgvalloss stands for the validation loss value on i th epoch\n",
    "                if es(network, avg_valloss):\n",
    "                    done = True\n",
    "                if avg_loss < best_val_loss:\n",
    "                    best_val_loss = avg_loss\n",
    "                    torch.save({\n",
    "                                'epoch': epoch+1,\n",
    "                                'model_state_dict': network.state_dict(),\n",
    "                                'optimizer_state_dict': optimizer.state_dict()\n",
    "                                \n",
    "                }, PATH)\n",
    "                wandb.log({\"validation_loss\":avg_valloss, \"epoch\": epoch})\n",
    "        \n",
    "        \n",
    "        \n",
    "        test()\n",
    "\n",
    "resnet_predictions = []\n",
    "def test():\n",
    "    network = build_resnet()\n",
    "    best_checkpoint = torch.load('./cifar_net.pth')\n",
    "    best_epoch = best_checkpoint[\"epoch\"]\n",
    "    print(\"Best epoch\",best_epoch)\n",
    "    \n",
    "\n",
    "    network.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    train_dataloader,test_dataloader,val_dataloader = build_dataset(32)\n",
    "    for epoch in range(best_epoch):\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_dataloader:\n",
    "                images = images.to(device)\n",
    "                outputs = network(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                resnet_predictions.extend(predicted.cpu().numpy())\n",
    "                y_pred.extend(predicted.cpu().numpy()) # bu benim ust mlp ye koyacagim input oluyor su an\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "            \n",
    "\n",
    "            # Convert lists to tensors for calculation\n",
    "            y_true_tensor = torch.tensor(y_true)\n",
    "            y_pred_tensor = torch.tensor(y_pred)\n",
    "            \n",
    "            # Calculating precision, recall, and F1 score using PyTorch\n",
    "            #TP = ((y_pred_tensor == 1) & (y_true_tensor == 1)).sum().item()\n",
    "            #FP = ((y_pred_tensor == 1) & (y_true_tensor == 0)).sum().item()\n",
    "            #FN = ((y_pred_tensor == 0) & (y_true_tensor == 1)).sum().item()\n",
    "\n",
    "            #precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "            #recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "            #f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            #auc = np.round(roc_auc_score(y_true, y_pred), 3)\n",
    "\n",
    "            #print(f'Precision: {precision}')\n",
    "            #print(f'Recall: {recall}')\n",
    "            #print(f'F1 Score: {f1}')\n",
    "            \n",
    "            #wandb.log({\"precision\":precision})\n",
    "            #wandb.log({\"recall\":recall})\n",
    "            #wandb.log({\"f1 score\":f1})\n",
    "            #wandb.log({\"AUC\":auc})\n",
    "\n",
    "test()\n",
    "print(len(resnet_predictions))\n",
    "print(resnet_predictions)\n",
    "\n",
    "\n",
    "\n",
    "class EnsembeResult(nn.Module): # This neural network merges the \n",
    "\n",
    "    def __init__(self,model_resnet,model_catboost):\n",
    "        super(EnsembeResult,self).__init__()\n",
    "        self.model_resnet = model_resnet\n",
    "        self.model_catboost = model_catboost\n",
    "        self.classifier = nn.Linear(2,1)\n",
    "\n",
    "    def forward(self,x1,x2):\n",
    "        x1 = self.model_resnet(x1)\n",
    "        x2 = self.model_catboost(x2)\n",
    "        x = torch.cat((x1,x2),dim=1)\n",
    "        x = self.classifier(F.relu(x))\n",
    "        return x    \n",
    "    \n",
    "\n",
    "# Create models and load state_dicts    \n",
    "#numericalClassifier = NumericalClassifier()\n",
    "modelResnet50 = build_resnet()\n",
    "# Load state dicts\n",
    "PATH = './cifar_net.pth'\n",
    "#numericalClassifier.load_state_dict(torch.load(PATH))\n",
    "#modelResnet50.load_state_dict(torch.load(PATH))\n",
    "\n",
    "#model = EnsembeResult(numericalClassifier, modelResnet50)\n",
    "\n",
    "\n",
    "\n",
    "#output = model(x1, x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader,test_dataloader,val_dataloader = build_dataset(32)\n",
    "for batch,val in test_dataloader:\n",
    "    print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'grid',\n",
      " 'metric': {'goal': 'minimize', 'name': 'loss'},\n",
      " 'parameters': {'batch_size': {'values': [32]},\n",
      "                'epochs': {'values': [1, 2]},\n",
      "                'learning_rate': {'values': [0.001]},\n",
      "                'optimizer': {'values': ['adam']}}}\n",
      "Create sweep with ID: o8erkbja\n",
      "Sweep URL: https://wandb.ai/alphanhilal-university-of-sussex/Resnet50%20Output/sweeps/o8erkbja\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid'\n",
    "    }\n",
    "\n",
    "metric = {\n",
    "    'name': 'loss',\n",
    "    'goal': 'minimize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "parameters_dict = {\n",
    "    'optimizer': {\n",
    "        'values': ['adam']\n",
    "        },\n",
    "    'learning_rate': {\n",
    "        \"values\" : [0.001] # 0.0001 vermeyi bi dene bakalim\n",
    "      },\n",
    "      'batch_size': {\n",
    "        \"values\" : [32]\n",
    "      },\n",
    "      \"epochs\" : {\n",
    "        \"values\" : [1,2]\n",
    "      }\n",
    "    }\n",
    " \n",
    "sweep_config['parameters'] = parameters_dict\n",
    "\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(sweep_config)\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"Resnet50 Output\")\n",
    "\n",
    "#wandb.agent(sweep_id, train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ae423\\AppData\\Local\\Temp\\ipykernel_23504\\3278508086.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_mass_df.rename(columns={\"breast_density\":\"breast density\"},inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch 0 | Batch 0 | Loss   0.71\n",
      "\tEpoch 0 | Batch 32 | Loss   0.71\n",
      "\tEpoch 0 | Batch 64 | Loss   0.71\n",
      "Epoch 0 | Loss   0.71\n",
      "Precision: 0\n",
      "Recall: 0.0\n",
      "F1 Score: 0\n",
      "\tEpoch 1 | Batch 0 | Loss   0.70\n",
      "\tEpoch 1 | Batch 32 | Loss   0.70\n",
      "\tEpoch 1 | Batch 64 | Loss   0.71\n",
      "Epoch 1 | Loss   0.71\n",
      "Precision: 0\n",
      "Recall: 0.0\n",
      "F1 Score: 0\n",
      "\tEpoch 2 | Batch 0 | Loss   0.72\n",
      "\tEpoch 2 | Batch 32 | Loss   0.73\n",
      "\tEpoch 2 | Batch 64 | Loss   0.70\n",
      "Epoch 2 | Loss   0.71\n",
      "Precision: 0\n",
      "Recall: 0.0\n",
      "F1 Score: 0\n",
      "\tEpoch 3 | Batch 0 | Loss   0.71\n",
      "\tEpoch 3 | Batch 32 | Loss   0.73\n",
      "\tEpoch 3 | Batch 64 | Loss   0.72\n",
      "Epoch 3 | Loss   0.71\n",
      "Precision: 0\n",
      "Recall: 0.0\n",
      "F1 Score: 0\n",
      "\tEpoch 4 | Batch 0 | Loss   0.70\n",
      "\tEpoch 4 | Batch 32 | Loss   0.69\n",
      "\tEpoch 4 | Batch 64 | Loss   0.71\n",
      "Epoch 4 | Loss   0.71\n",
      "Precision: 0\n",
      "Recall: 0.0\n",
      "F1 Score: 0\n",
      "\tEpoch 5 | Batch 0 | Loss   0.71\n",
      "\tEpoch 5 | Batch 32 | Loss   0.70\n",
      "\tEpoch 5 | Batch 64 | Loss   0.70\n",
      "Epoch 5 | Loss   0.71\n",
      "Precision: 0\n",
      "Recall: 0.0\n",
      "F1 Score: 0\n",
      "\tEpoch 6 | Batch 0 | Loss   0.70\n",
      "\tEpoch 6 | Batch 32 | Loss   0.69\n",
      "\tEpoch 6 | Batch 64 | Loss   0.72\n",
      "Epoch 6 | Loss   0.71\n",
      "Precision: 0\n",
      "Recall: 0.0\n",
      "F1 Score: 0\n",
      "\tEpoch 7 | Batch 0 | Loss   0.73\n",
      "\tEpoch 7 | Batch 32 | Loss   0.70\n",
      "\tEpoch 7 | Batch 64 | Loss   0.73\n",
      "Epoch 7 | Loss   0.71\n",
      "Precision: 0\n",
      "Recall: 0.0\n",
      "F1 Score: 0\n",
      "\tEpoch 8 | Batch 0 | Loss   0.71\n",
      "\tEpoch 8 | Batch 32 | Loss   0.71\n",
      "\tEpoch 8 | Batch 64 | Loss   0.72\n",
      "Epoch 8 | Loss   0.71\n",
      "Precision: 0\n",
      "Recall: 0.0\n",
      "F1 Score: 0\n",
      "\tEpoch 9 | Batch 0 | Loss   0.70\n",
      "\tEpoch 9 | Batch 32 | Loss   0.71\n",
      "\tEpoch 9 | Batch 64 | Loss   0.72\n",
      "Epoch 9 | Loss   0.71\n",
      "Precision: 0\n",
      "Recall: 0.0\n",
      "F1 Score: 0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "numerical_predictions = []\n",
    "def pathology_encoder(val):\n",
    "    return \"MALIGNANT\" if val == \"MALIGNANT\" else \"NORMAL\"\n",
    "\n",
    "calc_df = pd.read_csv(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\calc_case_description_train_set.csv\")\n",
    "c_test = pd.read_csv(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\calc_case_description_test_set.csv\")\n",
    "calc_df[\"pathology\"] = calc_df[\"pathology\"].map(pathology_encoder)\n",
    "cols_to_be_used = [\"breast density\",\"left or right breast\",\"calc type\",\"calc distribution\",\"pathology\"]\n",
    "new_calc_df = calc_df[cols_to_be_used]\n",
    "\n",
    "mass_df = pd.read_csv(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\mass_case_description_train_set.csv\")\n",
    "m_test = pd.read_csv(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\mass_case_description_test_set.csv\")\n",
    "mass_df[\"pathology\"] = mass_df[\"pathology\"].map(pathology_encoder)\n",
    "cols_to_be_used = [\"breast_density\",\"left or right breast\",\"mass shape\",\"mass margins\",\"pathology\"]\n",
    "new_mass_df = mass_df[cols_to_be_used]\n",
    "new_mass_df.rename(columns={\"breast_density\":\"breast density\"},inplace=True)\n",
    "\n",
    "bc_df = pd.concat([new_calc_df,new_mass_df])\n",
    "lbl_encoder = LabelEncoder()\n",
    "bc_df['left or right breast'] = lbl_encoder.fit_transform(bc_df['left or right breast'])\n",
    "bc_df['calc type'] = lbl_encoder.fit_transform(bc_df['calc type'])\n",
    "bc_df[\"calc distribution\"] = lbl_encoder.fit_transform(bc_df['left or right breast'])\n",
    "bc_df['pathology'] = lbl_encoder.fit_transform(bc_df['pathology'])\n",
    "bc_df['mass shape'] = lbl_encoder.fit_transform(bc_df['mass shape'])\n",
    "bc_df['mass margins'] = lbl_encoder.fit_transform(bc_df['mass margins'])\n",
    "\n",
    "bc_df[\"breast density\"] = bc_df[\"breast density\"].astype(float)\n",
    "\n",
    "cols = [\"breast density\",'left or right breast', 'calc type','calc distribution', 'mass shape', 'mass margins']\n",
    "scaler = StandardScaler()\n",
    "bc_df[cols] = scaler.fit_transform(bc_df[cols])\n",
    "\n",
    "x_train,y_train = bc_df[\"pathology\"], bc_df[\"pathology\"]\n",
    "df = pd.concat([c_test,m_test])\n",
    "df = df[[\"breast density\",\"left or right breast\",\"calc type\",\"calc distribution\",\"pathology\",\"mass shape\",\"mass margins\"]] \n",
    "x_test,y_test = df.drop(\"pathology\"), df[\"pathology\"]\n",
    "\n",
    "class NumericalClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(6, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.linear_relu_stack(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "y_train = np.reshape(y_train,(y_train.shape[0],1))\n",
    "y_test = np.reshape(y_test,(y_test.shape[0],1))\n",
    "\n",
    "\n",
    "train_set = np.concatenate((x_train,y_train),axis=1)\n",
    "test_set = np.concatenate((x_test,y_test),axis=1)\n",
    "train_set = torch.tensor(train_set, dtype=torch.float32)\n",
    "test_set = torch.tensor(test_set, dtype=torch.float32)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_set,  batch_size=batch_size, shuffle=False)\n",
    "epochs = 10\n",
    "optimizer = build_optimizer(NumericalClassifier(),\"adam\",learning_rate=0.001)\n",
    "model = NumericalClassifier()\n",
    "i = 0\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    for batch_num, input_data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x, y = input_data[:,:6], input_data[:,6]\n",
    "        output = model(x)\n",
    "        y = torch.reshape(y,(y.shape[0],1))\n",
    "        loss = nn.BCELoss()(output, y)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_num % 32 == 0:\n",
    "            print('\\tEpoch %d | Batch %d | Loss %6.2f' % (epoch, batch_num, loss.item()))\n",
    "    print('Epoch %d | Loss %6.2f' % (epoch, sum(losses)/len(losses)))\n",
    "    \n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for values in test_loader:\n",
    "            labels = values[:,6] \n",
    "            outputs = model(values[:,:6])\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            numerical_predictions.extend(predicted.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy()) # buradaki deger de ayni sekilde bir sonraki mlp ye koyacagim ikinci input oluyor.\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "        # Convert lists to tensors for calculation\n",
    "        y_true_tensor = torch.tensor(y_true)\n",
    "        y_pred_tensor = torch.tensor(y_pred)\n",
    "\n",
    "\n",
    "        # Calculating precision, recall, and F1 score using PyTorch\n",
    "        TP = ((y_pred_tensor == 1) & (y_true_tensor == 1)).sum().item()\n",
    "        FP = ((y_pred_tensor == 1) & (y_true_tensor == 0)).sum().item()\n",
    "        FN = ((y_pred_tensor == 0) & (y_true_tensor == 1)).sum().item()\n",
    "\n",
    "        precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "        recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        auc = np.round(roc_auc_score(y_true, y_pred), 3)\n",
    "\n",
    "        print(f'Precision: {precision}')\n",
    "        print(f'Recall: {recall}')\n",
    "        print(f'F1 Score: {f1}')\n",
    "\n",
    "print(numerical_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5730"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(numerical_predictions)):\n",
    "    numerical_predictions[i] = numerical_predictions[i].item()\n",
    "len(numerical_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NumericalClassifier' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(x_test)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(predictions,y_test))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(precision_score(predictions,y_test))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NumericalClassifier' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "print(accuracy_score(predictions,y_test))\n",
    "print(precision_score(predictions,y_test))\n",
    "print(recall_score(predictions,y_test))\n",
    "print(f1_score(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breast density</th>\n",
       "      <th>left or right breast</th>\n",
       "      <th>calc type</th>\n",
       "      <th>calc distribution</th>\n",
       "      <th>pathology</th>\n",
       "      <th>mass shape</th>\n",
       "      <th>mass margins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>AMORPHOUS</td>\n",
       "      <td>CLUSTERED</td>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>AMORPHOUS</td>\n",
       "      <td>CLUSTERED</td>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>PLEOMORPHIC</td>\n",
       "      <td>LINEAR</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>PLEOMORPHIC</td>\n",
       "      <td>LINEAR</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGIONAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>2</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>IRREGULAR</td>\n",
       "      <td>ILL_DEFINED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>2</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>ROUND</td>\n",
       "      <td>SPICULATED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>2</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>ROUND</td>\n",
       "      <td>SPICULATED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>2</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>IRREGULAR</td>\n",
       "      <td>SPICULATED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>2</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>IRREGULAR</td>\n",
       "      <td>SPICULATED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2864 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      breast density left or right breast    calc type calc distribution  \\\n",
       "0                  3                RIGHT    AMORPHOUS         CLUSTERED   \n",
       "1                  3                RIGHT    AMORPHOUS         CLUSTERED   \n",
       "2                  4                 LEFT  PLEOMORPHIC            LINEAR   \n",
       "3                  4                 LEFT  PLEOMORPHIC            LINEAR   \n",
       "4                  1                 LEFT          NaN          REGIONAL   \n",
       "...              ...                  ...          ...               ...   \n",
       "1313               2                RIGHT          NaN               NaN   \n",
       "1314               2                RIGHT          NaN               NaN   \n",
       "1315               2                RIGHT          NaN               NaN   \n",
       "1316               2                 LEFT          NaN               NaN   \n",
       "1317               2                 LEFT          NaN               NaN   \n",
       "\n",
       "      pathology mass shape mass margins  \n",
       "0     MALIGNANT        NaN          NaN  \n",
       "1     MALIGNANT        NaN          NaN  \n",
       "2        NORMAL        NaN          NaN  \n",
       "3        NORMAL        NaN          NaN  \n",
       "4        NORMAL        NaN          NaN  \n",
       "...         ...        ...          ...  \n",
       "1313  MALIGNANT  IRREGULAR  ILL_DEFINED  \n",
       "1314  MALIGNANT      ROUND   SPICULATED  \n",
       "1315  MALIGNANT      ROUND   SPICULATED  \n",
       "1316  MALIGNANT  IRREGULAR   SPICULATED  \n",
       "1317  MALIGNANT  IRREGULAR   SPICULATED  \n",
       "\n",
       "[2864 rows x 7 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
