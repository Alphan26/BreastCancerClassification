{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbG69QSD28qR"
   },
   "source": [
    "# Breast Cancer Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wsrtTwy28qS"
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn opencv-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch==2.0+cu117 --user -f https://download.pytorch.org/whl/cu117/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchvision==0.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yAZXXlHp28qS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import glob\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import random\n",
    "import cv2\n",
    "import sys\n",
    "from torchvision import models,transforms,datasets\n",
    "import time\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.folder import default_loader\n",
    "import torchvision\n",
    "from sklearn .metrics import roc_auc_score,accuracy_score,precision_score,recall_score,f1_score\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "os.environ[\"PYTORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hJtcehDm4H4Z",
    "outputId": "64b5758f-3074-4d9a-9f75-50ffc024f9d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA RTX A4000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.is_available()) # this should return true\n",
    "torch.cuda.get_device_name() # this should return your graphics card name. Ex) 'NVIDIA RTX A4000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hV1jmdLT5LKF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom zipfile import ZipFile \\n\\n # loading the temp.zip and creating a zip object \\nwith ZipFile(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis_ddsm.zip\", \\'r\\') as zObject: \\n    zObject.extractall() \\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # importing the zipfile module \n",
    "\"\"\"\n",
    "from zipfile import ZipFile \n",
    "\n",
    " # loading the temp.zip and creating a zip object \n",
    "with ZipFile(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis_ddsm.zip\", 'r') as zObject: \n",
    "    zObject.extractall() \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.248386...\n",
       "2     CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.267213...\n",
       "11    CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.210396...\n",
       "12    CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.749566...\n",
       "15    CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.987658...\n",
       "Name: image_path, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dicom_data = pd.read_csv(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\dicom_info.csv\")\n",
    "\n",
    "full_mammogram_images = dicom_data[dicom_data.SeriesDescription == 'full mammogram images'].image_path\n",
    "full_mammogram_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ae423\\AppData\\Local\\Temp\\ipykernel_27552\\2910366824.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  mass_train.iloc[0][11].split(\"/\")[2]\n"
     ]
    }
   ],
   "source": [
    "# load the mass dataset\n",
    "mass_train = pd.read_csv('C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\mass_case_description_train_set.csv')\n",
    "mass_test = pd.read_csv('C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\mass_case_description_test_set.csv')\n",
    "\n",
    "#mass_train.head()\n",
    "mass_train.iloc[0][11].split(\"/\")[2]\n",
    "\n",
    "# fix image paths\n",
    "def fix_image_path(data):\n",
    " #   correct dicom paths to correct image paths\n",
    "  for index, img in enumerate(data.values):\n",
    "    img_name = img[11].split(\"/\")[2]\n",
    "    new_path = \"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\jpeg\\\\\" + img_name\n",
    "    data.iloc[index,11] = new_path\n",
    "      \n",
    "# apply to datasets\n",
    "fix_image_path(mass_train)\n",
    "fix_image_path(mass_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "calc_train = pd.read_csv('C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\calc_case_description_train_set.csv')\n",
    "calc_test = pd.read_csv('C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\calc_case_description_test_set.csv')\n",
    "\n",
    "fix_image_path(calc_train)\n",
    "fix_image_path(calc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002\n",
      "544\n",
      "1546\n"
     ]
    }
   ],
   "source": [
    "temp_calc_train = calc_train[[\"image file path\",\"pathology\"]]\n",
    "calc_normal = []\n",
    "calc_malignant = []\n",
    "for row,col in temp_calc_train.iterrows():\n",
    "    if col[\"pathology\"] == \"MALIGNANT\":\n",
    "        calc_malignant.append(col[\"image file path\"])\n",
    "    else:\n",
    "        calc_normal.append(col[\"image file path\"])\n",
    "\n",
    "print(len(calc_normal))\n",
    "print(len(calc_malignant))\n",
    "print(len(temp_calc_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>breast density</th>\n",
       "      <th>left or right breast</th>\n",
       "      <th>image view</th>\n",
       "      <th>abnormality id</th>\n",
       "      <th>abnormality type</th>\n",
       "      <th>calc type</th>\n",
       "      <th>calc distribution</th>\n",
       "      <th>assessment</th>\n",
       "      <th>pathology</th>\n",
       "      <th>subtlety</th>\n",
       "      <th>image file path</th>\n",
       "      <th>cropped image file path</th>\n",
       "      <th>ROI mask file path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P_00038</td>\n",
       "      <td>2</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>calcification</td>\n",
       "      <td>PUNCTATE-PLEOMORPHIC</td>\n",
       "      <td>CLUSTERED</td>\n",
       "      <td>4</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>2</td>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>Calc-Test_P_00038_LEFT_CC_1/1.3.6.1.4.1.9590.1...</td>\n",
       "      <td>Calc-Test_P_00038_LEFT_CC_1/1.3.6.1.4.1.9590.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_00038</td>\n",
       "      <td>2</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>MLO</td>\n",
       "      <td>1</td>\n",
       "      <td>calcification</td>\n",
       "      <td>PUNCTATE-PLEOMORPHIC</td>\n",
       "      <td>CLUSTERED</td>\n",
       "      <td>4</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>2</td>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>Calc-Test_P_00038_LEFT_MLO_1/1.3.6.1.4.1.9590....</td>\n",
       "      <td>Calc-Test_P_00038_LEFT_MLO_1/1.3.6.1.4.1.9590....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_00038</td>\n",
       "      <td>2</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>calcification</td>\n",
       "      <td>VASCULAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>BENIGN_WITHOUT_CALLBACK</td>\n",
       "      <td>5</td>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>Calc-Test_P_00038_RIGHT_CC_1/1.3.6.1.4.1.9590....</td>\n",
       "      <td>Calc-Test_P_00038_RIGHT_CC_1/1.3.6.1.4.1.9590....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P_00038</td>\n",
       "      <td>2</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>CC</td>\n",
       "      <td>2</td>\n",
       "      <td>calcification</td>\n",
       "      <td>VASCULAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>BENIGN_WITHOUT_CALLBACK</td>\n",
       "      <td>5</td>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>Calc-Test_P_00038_RIGHT_CC_2/1.3.6.1.4.1.9590....</td>\n",
       "      <td>Calc-Test_P_00038_RIGHT_CC_2/1.3.6.1.4.1.9590....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P_00038</td>\n",
       "      <td>2</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>MLO</td>\n",
       "      <td>1</td>\n",
       "      <td>calcification</td>\n",
       "      <td>VASCULAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>BENIGN_WITHOUT_CALLBACK</td>\n",
       "      <td>5</td>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>Calc-Test_P_00038_RIGHT_MLO_1/1.3.6.1.4.1.9590...</td>\n",
       "      <td>Calc-Test_P_00038_RIGHT_MLO_1/1.3.6.1.4.1.9590...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>P_02464</td>\n",
       "      <td>2</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>MLO</td>\n",
       "      <td>1</td>\n",
       "      <td>calcification</td>\n",
       "      <td>FINE_LINEAR_BRANCHING</td>\n",
       "      <td>CLUSTERED</td>\n",
       "      <td>0</td>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>4</td>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>Calc-Test_P_02464_RIGHT_MLO_1/1.3.6.1.4.1.9590...</td>\n",
       "      <td>Calc-Test_P_02464_RIGHT_MLO_1/1.3.6.1.4.1.9590...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>P_02498</td>\n",
       "      <td>4</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>calcification</td>\n",
       "      <td>PUNCTATE</td>\n",
       "      <td>CLUSTERED</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>3</td>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>Calc-Test_P_02498_RIGHT_CC_1/1.3.6.1.4.1.9590....</td>\n",
       "      <td>Calc-Test_P_02498_RIGHT_CC_1/1.3.6.1.4.1.9590....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>P_02498</td>\n",
       "      <td>4</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>MLO</td>\n",
       "      <td>1</td>\n",
       "      <td>calcification</td>\n",
       "      <td>PUNCTATE</td>\n",
       "      <td>CLUSTERED</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>3</td>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>Calc-Test_P_02498_RIGHT_MLO_1/1.3.6.1.4.1.9590...</td>\n",
       "      <td>Calc-Test_P_02498_RIGHT_MLO_1/1.3.6.1.4.1.9590...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>P_02501</td>\n",
       "      <td>3</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>calcification</td>\n",
       "      <td>PLEOMORPHIC</td>\n",
       "      <td>CLUSTERED</td>\n",
       "      <td>0</td>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>3</td>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>Calc-Test_P_02501_RIGHT_CC_1/1.3.6.1.4.1.9590....</td>\n",
       "      <td>Calc-Test_P_02501_RIGHT_CC_1/1.3.6.1.4.1.9590....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>P_02501</td>\n",
       "      <td>3</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>MLO</td>\n",
       "      <td>1</td>\n",
       "      <td>calcification</td>\n",
       "      <td>PLEOMORPHIC</td>\n",
       "      <td>CLUSTERED</td>\n",
       "      <td>0</td>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>3</td>\n",
       "      <td>C:\\Users\\ae423\\OneDrive - University of Sussex...</td>\n",
       "      <td>Calc-Test_P_02501_RIGHT_MLO_1/1.3.6.1.4.1.9590...</td>\n",
       "      <td>Calc-Test_P_02501_RIGHT_MLO_1/1.3.6.1.4.1.9590...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    patient_id  breast density left or right breast image view  \\\n",
       "0      P_00038               2                 LEFT         CC   \n",
       "1      P_00038               2                 LEFT        MLO   \n",
       "2      P_00038               2                RIGHT         CC   \n",
       "3      P_00038               2                RIGHT         CC   \n",
       "4      P_00038               2                RIGHT        MLO   \n",
       "..         ...             ...                  ...        ...   \n",
       "321    P_02464               2                RIGHT        MLO   \n",
       "322    P_02498               4                RIGHT         CC   \n",
       "323    P_02498               4                RIGHT        MLO   \n",
       "324    P_02501               3                RIGHT         CC   \n",
       "325    P_02501               3                RIGHT        MLO   \n",
       "\n",
       "     abnormality id abnormality type              calc type calc distribution  \\\n",
       "0                 1    calcification   PUNCTATE-PLEOMORPHIC         CLUSTERED   \n",
       "1                 1    calcification   PUNCTATE-PLEOMORPHIC         CLUSTERED   \n",
       "2                 1    calcification               VASCULAR               NaN   \n",
       "3                 2    calcification               VASCULAR               NaN   \n",
       "4                 1    calcification               VASCULAR               NaN   \n",
       "..              ...              ...                    ...               ...   \n",
       "321               1    calcification  FINE_LINEAR_BRANCHING         CLUSTERED   \n",
       "322               1    calcification               PUNCTATE         CLUSTERED   \n",
       "323               1    calcification               PUNCTATE         CLUSTERED   \n",
       "324               1    calcification            PLEOMORPHIC         CLUSTERED   \n",
       "325               1    calcification            PLEOMORPHIC         CLUSTERED   \n",
       "\n",
       "     assessment                pathology  subtlety  \\\n",
       "0             4                   BENIGN         2   \n",
       "1             4                   BENIGN         2   \n",
       "2             2  BENIGN_WITHOUT_CALLBACK         5   \n",
       "3             2  BENIGN_WITHOUT_CALLBACK         5   \n",
       "4             2  BENIGN_WITHOUT_CALLBACK         5   \n",
       "..          ...                      ...       ...   \n",
       "321           0                MALIGNANT         4   \n",
       "322           0                   BENIGN         3   \n",
       "323           0                   BENIGN         3   \n",
       "324           0                MALIGNANT         3   \n",
       "325           0                MALIGNANT         3   \n",
       "\n",
       "                                       image file path  \\\n",
       "0    C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "1    C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "2    C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "3    C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "4    C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "..                                                 ...   \n",
       "321  C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "322  C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "323  C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "324  C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "325  C:\\Users\\ae423\\OneDrive - University of Sussex...   \n",
       "\n",
       "                               cropped image file path  \\\n",
       "0    Calc-Test_P_00038_LEFT_CC_1/1.3.6.1.4.1.9590.1...   \n",
       "1    Calc-Test_P_00038_LEFT_MLO_1/1.3.6.1.4.1.9590....   \n",
       "2    Calc-Test_P_00038_RIGHT_CC_1/1.3.6.1.4.1.9590....   \n",
       "3    Calc-Test_P_00038_RIGHT_CC_2/1.3.6.1.4.1.9590....   \n",
       "4    Calc-Test_P_00038_RIGHT_MLO_1/1.3.6.1.4.1.9590...   \n",
       "..                                                 ...   \n",
       "321  Calc-Test_P_02464_RIGHT_MLO_1/1.3.6.1.4.1.9590...   \n",
       "322  Calc-Test_P_02498_RIGHT_CC_1/1.3.6.1.4.1.9590....   \n",
       "323  Calc-Test_P_02498_RIGHT_MLO_1/1.3.6.1.4.1.9590...   \n",
       "324  Calc-Test_P_02501_RIGHT_CC_1/1.3.6.1.4.1.9590....   \n",
       "325  Calc-Test_P_02501_RIGHT_MLO_1/1.3.6.1.4.1.9590...   \n",
       "\n",
       "                                    ROI mask file path  \n",
       "0    Calc-Test_P_00038_LEFT_CC_1/1.3.6.1.4.1.9590.1...  \n",
       "1    Calc-Test_P_00038_LEFT_MLO_1/1.3.6.1.4.1.9590....  \n",
       "2    Calc-Test_P_00038_RIGHT_CC_1/1.3.6.1.4.1.9590....  \n",
       "3    Calc-Test_P_00038_RIGHT_CC_2/1.3.6.1.4.1.9590....  \n",
       "4    Calc-Test_P_00038_RIGHT_MLO_1/1.3.6.1.4.1.9590...  \n",
       "..                                                 ...  \n",
       "321  Calc-Test_P_02464_RIGHT_MLO_1/1.3.6.1.4.1.9590...  \n",
       "322  Calc-Test_P_02498_RIGHT_CC_1/1.3.6.1.4.1.9590....  \n",
       "323  Calc-Test_P_02498_RIGHT_MLO_1/1.3.6.1.4.1.9590...  \n",
       "324  Calc-Test_P_02501_RIGHT_CC_1/1.3.6.1.4.1.9590....  \n",
       "325  Calc-Test_P_02501_RIGHT_MLO_1/1.3.6.1.4.1.9590...  \n",
       "\n",
       "[326 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681\n",
      "637\n",
      "1318\n"
     ]
    }
   ],
   "source": [
    "new_df = mass_train[[\"image file path\",\"pathology\"]]\n",
    "\n",
    "normal_path = []\n",
    "malignant_path = []\n",
    "for row,col in new_df.iterrows():\n",
    "    if col[\"pathology\"] == \"MALIGNANT\":\n",
    "        # put this file to the malignant folder\n",
    "        malignant_path.append(col[\"image file path\"])\n",
    "    else:\n",
    "        normal_path.append(col[\"image file path\"])\n",
    "\n",
    "print(len(normal_path))\n",
    "print(len(malignant_path))\n",
    "print(len(new_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "128\n",
      "295\n",
      "296\n",
      "86\n",
      "125\n"
     ]
    }
   ],
   "source": [
    "path = \"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\\"\n",
    "print(len(os.listdir(os.path.join(path,\"cbis-test\\\\malignant\"))))\n",
    "print(len(os.listdir(os.path.join(path,\"cbis-test\\\\normal\"))))\n",
    "print(len(os.listdir(os.path.join(path,\"cbis-train\\\\malignant\"))))\n",
    "print(len(os.listdir(os.path.join(path,\"cbis-train\\\\normal\"))))\n",
    "print(len(os.listdir(os.path.join(path,\"cbis-val\\\\malignant\"))))\n",
    "print(len(os.listdir(os.path.join(path,\"cbis-val\\\\normal\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "temp,test = train_test_split(last_df, test_size=0.1,shuffle= True)\n",
    "train,val = train_test_split(temp, test_size=0.1,shuffle= True)\n",
    "\n",
    "print(len(train))\n",
    "print(len(val))\n",
    "print(len(test))\n",
    "\"\"\"\n",
    "last_df = pd.concat([temp_calc_train,new_df])\n",
    "calc_test = calc_test[[\"image file path\",\"pathology\"]]\n",
    "mass_test = mass_test[[\"image file path\",\"pathology\"]]\n",
    "new_test = pd.concat([calc_test,mass_test])\n",
    "\n",
    "train = last_df[:2160]\n",
    "val = last_df[2160:]\n",
    "test_df = new_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport shutil\\n\\ndef write_into_train_folder():\\n    for row,col in train.iterrows():\\n        for img_name in os.listdir(col[\"image file path\"]):\\n            img_path = col[\"image file path\"] + \"\\\\\" + img_name\\n            if col[\"pathology\"] == \"MALIGNANT\":\\n                # put this file to the malignant folder\\n                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-train\\\\malignant\")\\n            else:\\n                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-train\\\\normal\")\\n                # put it into normal folder\\n\\n\\ndef write_into_val_folder():\\n    for row,col in val.iterrows():\\n        for img_name in os.listdir(col[\"image file path\"]):\\n            img_path = col[\"image file path\"] + \"\\\\\" + img_name\\n            if col[\"pathology\"] == \"MALIGNANT\":\\n                # put this file to the malignant folder\\n                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-val\\\\malignant\")\\n            else:\\n                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-val\\\\normal\")\\n                # put it into normal folder\\n\\n\\ndef write_into_test_folder():\\n    for row,col in test.iterrows():\\n        for img_name in os.listdir(col[\"image file path\"]):\\n            img_path = col[\"image file path\"] + \"\\\\\" + img_name\\n            if col[\"pathology\"] == \"MALIGNANT\":\\n                # put this file to the malignant folder\\n                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-test\\\\malignant\")\\n            else:\\n                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-test\\\\normal\")\\n                # put it into normal folder\\n\\nwrite_into_train_folder()\\nwrite_into_val_folder()\\nwrite_into_test_folder()\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import shutil\n",
    "\n",
    "def write_into_train_folder():\n",
    "    for row,col in train.iterrows():\n",
    "        for img_name in os.listdir(col[\"image file path\"]):\n",
    "            img_path = col[\"image file path\"] + \"\\\\\" + img_name\n",
    "            if col[\"pathology\"] == \"MALIGNANT\":\n",
    "                # put this file to the malignant folder\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-train\\\\malignant\")\n",
    "            else:\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-train\\\\normal\")\n",
    "                # put it into normal folder\n",
    "\n",
    "\n",
    "def write_into_val_folder():\n",
    "    for row,col in val.iterrows():\n",
    "        for img_name in os.listdir(col[\"image file path\"]):\n",
    "            img_path = col[\"image file path\"] + \"\\\\\" + img_name\n",
    "            if col[\"pathology\"] == \"MALIGNANT\":\n",
    "                # put this file to the malignant folder\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-val\\\\malignant\")\n",
    "            else:\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-val\\\\normal\")\n",
    "                # put it into normal folder\n",
    "\n",
    "\n",
    "def write_into_test_folder():\n",
    "    for row,col in test.iterrows():\n",
    "        for img_name in os.listdir(col[\"image file path\"]):\n",
    "            img_path = col[\"image file path\"] + \"\\\\\" + img_name\n",
    "            if col[\"pathology\"] == \"MALIGNANT\":\n",
    "                # put this file to the malignant folder\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-test\\\\malignant\")\n",
    "            else:\n",
    "                shutil.copy(img_path,\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-test\\\\normal\")\n",
    "                # put it into normal folder\n",
    "\n",
    "write_into_train_folder()\n",
    "write_into_val_folder()\n",
    "write_into_test_folder()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os \\n#os.makedirs(\"cbis-train/normal\")\\nos.makedirs(\"cbis-train/malignant\")\\nos.makedirs(\"cbis-val/normal\")\\nos.makedirs(\"cbis-val/malignant\")\\nos.makedirs(\"cbis-test/normal\")\\nos.makedirs(\"cbis-test/malignant\")\\n\\ndef write_inside_folder(df):\\n    for folder in df:\\n        for file in os.listdir(folder):\\n            cv2.imwrite(folder,file)\\n\\n#write_inside_folder(train)\\n#write_inside_folder(val)\\n#write_inside_folder(test)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import os \n",
    "#os.makedirs(\"cbis-train/normal\")\n",
    "os.makedirs(\"cbis-train/malignant\")\n",
    "os.makedirs(\"cbis-val/normal\")\n",
    "os.makedirs(\"cbis-val/malignant\")\n",
    "os.makedirs(\"cbis-test/normal\")\n",
    "os.makedirs(\"cbis-test/malignant\")\n",
    "\n",
    "def write_inside_folder(df):\n",
    "    for folder in df:\n",
    "        for file in os.listdir(folder):\n",
    "            cv2.imwrite(folder,file)\n",
    "\n",
    "#write_inside_folder(train)\n",
    "#write_inside_folder(val)\n",
    "#write_inside_folder(test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: alphanhilal (alphanhilal-university-of-sussex). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ae423\\OneDrive - University of Sussex\\Desktop\\AlphanElmasDissertation\\wandb\\run-20240824_213512-c6pydgov</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanhilal-university-of-sussex/Pretrained%20Output/runs/c6pydgov' target=\"_blank\">peach-aardvark-17</a></strong> to <a href='https://wandb.ai/alphanhilal-university-of-sussex/Pretrained%20Output' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanhilal-university-of-sussex/Pretrained%20Output' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/Pretrained%20Output</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanhilal-university-of-sussex/Pretrained%20Output/runs/c6pydgov' target=\"_blank\">https://wandb.ai/alphanhilal-university-of-sussex/Pretrained%20Output/runs/c6pydgov</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"Pretrained Output\",\n",
    "    # Track hyperparameters and run metadata\n",
    ")\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLAHE():\n",
    "    \n",
    "    def __init__(self, clipLimit=2.0, tileGridSize=(16,16)):\n",
    "        super().__init__\n",
    "        self.clipLimit = clipLimit\n",
    "        self.tileGridSize = tileGridSize\n",
    "\n",
    "    def __call__(self,sample):\n",
    "      img = np.array(sample)\n",
    "      img = np.moveaxis(img,0,2)\n",
    "      imgray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "      imgray = imgray.astype(np.uint16)\n",
    "      clahe = cv2.createCLAHE(clipLimit=self.clipLimit, tileGridSize=self.tileGridSize)\n",
    "      new_img = clahe.apply(imgray)\n",
    "      new_img = cv2.cvtColor(new_img, cv2.COLOR_GRAY2BGR)\n",
    "      new_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB)\n",
    "      new_img = new_img.astype(np.float32)\n",
    "      new_img = np.moveaxis(new_img,2,0)\n",
    "      tensor = torch.tensor(new_img)\n",
    "      #print(img.shape)\n",
    "      return tensor\n",
    "\n",
    "\n",
    "class GaussianNoise():\n",
    "\n",
    "    def __init__(self,mean=0,stddev=0.01):\n",
    "        super().__init__\n",
    "        self.mean = mean\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def __call__(self,sample):\n",
    "        sample = sample.cpu()\n",
    "        input_array = sample.data.numpy()\n",
    "\n",
    "        noise = np.random.normal(loc=self.mean, scale=self.stddev, size=np.shape(input_array))\n",
    "\n",
    "        out = np.add(input_array, noise)\n",
    "\n",
    "        output_tensor = torch.from_numpy(out)\n",
    "        out_tensor = Variable(output_tensor)\n",
    "        out = out_tensor.cuda()\n",
    "        out = out.float()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_model = None\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.status = \"\"\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "        elif self.best_loss - val_loss >= self.min_delta:\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.status = f\"Improvement found, counter reset to {self.counter}\"\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            self.status = f\"No improvement in the last {self.counter} epochs\"\n",
    "            if self.counter >= self.patience:\n",
    "                self.status = f\"Early stopping triggered after {self.counter} epochs.\"\n",
    "                if self.restore_best_weights:\n",
    "                    model.load_state_dict(self.best_model)\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_predictions = [] # The outputs of predictions will be stored in this array\n",
    "numerical_predictions = [] # Numerical predictions will be stored in this array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_predictions = []\n",
    "def pathology_encoder(val):\n",
    "    return \"MALIGNANT\" if val == \"MALIGNANT\" else \"NORMAL\"\n",
    "\n",
    "calc_df = pd.read_csv(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\calc_case_description_train_set.csv\")\n",
    "c_test = pd.read_csv(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\calc_case_description_test_set.csv\")\n",
    "calc_df[\"pathology\"] = calc_df[\"pathology\"].map(pathology_encoder)\n",
    "cols_to_be_used = [\"breast density\",\"left or right breast\",\"calc type\",\"calc distribution\",\"pathology\"]\n",
    "new_calc_df = calc_df[cols_to_be_used]\n",
    "\n",
    "mass_df = pd.read_csv(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\mass_case_description_train_set.csv\")\n",
    "m_test = pd.read_csv(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\mass_case_description_test_set.csv\")\n",
    "mass_df[\"pathology\"] = mass_df[\"pathology\"].map(pathology_encoder)\n",
    "cols_to_be_used = [\"breast_density\",\"left or right breast\",\"mass shape\",\"mass margins\",\"pathology\"]\n",
    "new_mass_df = mass_df[cols_to_be_used]\n",
    "new_mass_df.rename(columns={\"breast_density\":\"breast density\"},inplace=True)\n",
    "\n",
    "bc_df = pd.concat([new_calc_df,new_mass_df])\n",
    "lbl_encoder = LabelEncoder()\n",
    "bc_df['left or right breast'] = lbl_encoder.fit_transform(bc_df['left or right breast'])\n",
    "bc_df['calc type'] = lbl_encoder.fit_transform(bc_df['calc type'])\n",
    "bc_df[\"calc distribution\"] = lbl_encoder.fit_transform(bc_df['left or right breast'])\n",
    "bc_df['pathology'] = lbl_encoder.fit_transform(bc_df['pathology'])\n",
    "bc_df['mass shape'] = lbl_encoder.fit_transform(bc_df['mass shape'])\n",
    "bc_df['mass margins'] = lbl_encoder.fit_transform(bc_df['mass margins'])\n",
    "\n",
    "bc_df[\"breast density\"] = bc_df[\"breast density\"].astype(float)\n",
    "\n",
    "cols = [\"breast density\",'left or right breast', 'calc type','calc distribution', 'mass shape', 'mass margins']\n",
    "scaler = StandardScaler()\n",
    "bc_df[cols] = scaler.fit_transform(bc_df[cols])\n",
    "\n",
    "x_train,y_train = bc_df[\"pathology\"], bc_df[\"pathology\"]\n",
    "df = pd.concat([c_test,m_test])\n",
    "df = df[[\"breast density\",\"left or right breast\",\"calc type\",\"calc distribution\",\"pathology\",\"mass shape\",\"mass margins\"]] \n",
    "x_test,y_test = df.drop(\"pathology\"), df[\"pathology\"]\n",
    "\n",
    "class NumericalClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(6, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.linear_relu_stack(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "y_train = np.reshape(y_train,(y_train.shape[0],1))\n",
    "y_test = np.reshape(y_test,(y_test.shape[0],1))\n",
    "\n",
    "\n",
    "train_set = np.concatenate((x_train,y_train),axis=1)\n",
    "test_set = np.concatenate((x_test,y_test),axis=1)\n",
    "train_set = torch.tensor(train_set, dtype=torch.float32)\n",
    "test_set = torch.tensor(test_set, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def train_numerical_classifier(resnet_input):\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = DataLoader(test_set,  batch_size=batch_size, shuffle=False)\n",
    "    epochs = 10\n",
    "    optimizer = build_optimizer(NumericalClassifier(),\"adam\",learning_rate=0.001)\n",
    "    model = NumericalClassifier()\n",
    "    i = 0\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        for batch_num, input_data in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            x, y = input_data[:,:6], input_data[:,6]\n",
    "            numerical_output = model(x)\n",
    "            #y = torch.reshape(y,(y.shape[0],1))\n",
    "            #loss = nn.BCELoss()(output, y)\n",
    "            #loss.backward()\n",
    "            #losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "            train_ensemble_model(resnet_input,numerical_output)\n",
    "            #if batch_num % 32 == 0:\n",
    "        #         print('\\tEpoch %d | Batch %d | Loss %6.2f' % (epoch, batch_num, loss.item()))\n",
    "        # print('Epoch %d | Loss %6.2f' % (epoch, sum(losses)/len(losses)))\n",
    "        \n",
    "        model.eval()\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        with torch.no_grad():\n",
    "            for values in test_loader:\n",
    "                labels = values[:,6] \n",
    "                outputs = model(values[:,:6])\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                numerical_predictions.extend(predicted.cpu().numpy())\n",
    "                y_pred.extend(predicted.cpu().numpy()) # buradaki deger de ayni sekilde bir sonraki mlp ye koyacagim ikinci input oluyor.\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "            # Convert lists to tensors for calculation\n",
    "            y_true_tensor = torch.tensor(y_true)\n",
    "            y_pred_tensor = torch.tensor(y_pred)\n",
    "\n",
    "\n",
    "            # Calculating precision, recall, and F1 score using PyTorch\n",
    "            TP = ((y_pred_tensor == 1) & (y_true_tensor == 1)).sum().item()\n",
    "            FP = ((y_pred_tensor == 1) & (y_true_tensor == 0)).sum().item()\n",
    "            FN = ((y_pred_tensor == 0) & (y_true_tensor == 1)).sum().item()\n",
    "\n",
    "            precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "            recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            auc = np.round(roc_auc_score(y_true, y_pred), 3)\n",
    "\n",
    "            print(f'Precision: {precision}')\n",
    "            print(f'Recall: {recall}')\n",
    "            print(f'F1 Score: {f1}')\n",
    "            \n",
    "\n",
    "def build_dataset(batch_size):\n",
    "   \n",
    "    transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # data augmentation\n",
    "    transforms.RandomRotation(degrees=(0,180)),\n",
    "    transforms.RandomAffine(degrees = 0, translate = (0.2, 0.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), # normalization\n",
    "    CLAHE(),\n",
    "    GaussianNoise()\n",
    "\n",
    "])\n",
    "    \n",
    "    train_dir = 'C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-train'\n",
    "    train_dataset = datasets.ImageFolder(train_dir, transforms_train)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    test_dir = 'C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-test'\n",
    "    test_dataset = datasets.ImageFolder(test_dir, transforms_train)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    val_dir = 'C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\cbis-val'\n",
    "    val_dataset = datasets.ImageFolder(val_dir, transforms_train)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    return train_dataloader,test_dataloader,val_dataloader\n",
    "\n",
    "\n",
    "def build_resnet():\n",
    "    model_ft = models.resnet50(weights='IMAGENET1K_V1')\n",
    "    for param in model_ft.parameters():\n",
    "        param.requires_grad = False\n",
    "    num_ftrs = model_ft.fc.in_features # 2048\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 1) # 16 values will be come for the merged model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    return model_ft.to(device)\n",
    "\n",
    "def build_densenet():\n",
    "    model_ft = models.densenet169(weights='IMAGENET1K_V1')\n",
    "    for param in model_ft.parameters():\n",
    "        param.requires_grad = False\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    return model_ft.to(device)\n",
    "\n",
    "        \n",
    "\n",
    "def build_optimizer(network, optimizer, learning_rate):\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(network.parameters(),\n",
    "                              lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(network.parameters(),\n",
    "                               lr=learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "def train_epoch(network, loader, optimizer):\n",
    "    cumu_loss = 0\n",
    "    for _, (data, target) in enumerate(loader): # batch batch butun datayi gezip loss degerlerini hesapliyorum\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        data,target = data.to(device),target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        network.to(device)\n",
    "        # ➡ Forward pass\n",
    "        prediction = network(data)\n",
    "        prediction = torch.squeeze(prediction)\n",
    "        new_target = torch.tensor(target, dtype=torch.float32)\n",
    "        # print(\"Labellar cudada mi\",new_target.is_cuda)\n",
    "        pred_probs = torch.sigmoid(prediction)\n",
    "        pred_labels = pred_probs.round()\n",
    "        # print(\"predictionlar cudada mi\", pred_labels.is_cuda)\n",
    "        #loss = loss_fn(pred_labels, new_target)\n",
    "        #cumu_loss += loss.item()\n",
    "        # ⬅ Backward pass + weight update\n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "        train_numerical_classifier(pred_labels)\n",
    "\n",
    "\n",
    "    return cumu_loss / len(loader)\n",
    "\n",
    "\n",
    "\n",
    "def train(config=None):\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        train_dataloader,test_dataloader,val_dataloader = build_dataset(config.batch_size)\n",
    "        network = build_resnet()\n",
    "        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)\n",
    "        scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.5, total_iters=10)\n",
    "        es = EarlyStopping()\n",
    "        best_val_loss = np.inf\n",
    "        PATH = './cifar_net.pth'\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            network.train(True)\n",
    "            avg_loss = train_epoch(network, train_dataloader, optimizer)\n",
    "            scheduler.step()\n",
    "            wandb.log({\"training_loss\": avg_loss, \"epoch\": epoch})    \n",
    "            running_vloss = 0\n",
    "            network.eval()\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            with torch.no_grad():\n",
    "                for i, vdata in enumerate(val_dataloader):\n",
    "                    vinputs, vlabels = vdata\n",
    "                    vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "                    voutputs = network(vinputs)\n",
    "                    vloss = loss_fn(voutputs, vlabels)\n",
    "                    running_vloss += vloss     \n",
    "\n",
    "                avg_valloss = running_vloss / (i + 1) # avgvalloss stands for the validation loss value on i th epoch\n",
    "                if es(network, avg_valloss):\n",
    "                    done = True\n",
    "                if avg_loss < best_val_loss:\n",
    "                    best_val_loss = avg_loss\n",
    "                    torch.save({\n",
    "                                'epoch': epoch+1,\n",
    "                                'model_state_dict': network.state_dict(),\n",
    "                                'optimizer_state_dict': optimizer.state_dict()\n",
    "                                \n",
    "                }, PATH)\n",
    "                wandb.log({\"validation_loss\":avg_valloss, \"epoch\": epoch})\n",
    "        \n",
    "        \n",
    "        \n",
    "        test()\n",
    "\n",
    "resnet_predictions = []\n",
    "def test():\n",
    "    network = build_resnet()\n",
    "    best_checkpoint = torch.load('./cifar_net.pth')\n",
    "    best_epoch = best_checkpoint[\"epoch\"]\n",
    "    print(\"Best epoch\",best_epoch)\n",
    "    \n",
    "\n",
    "    network.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    train_dataloader,test_dataloader,val_dataloader = build_dataset(32)\n",
    "    for epoch in range(best_epoch):\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_dataloader:\n",
    "                images = images.to(device)\n",
    "                outputs = network(images)\n",
    "                pred_prob = torch.sigmoid(outputs)\n",
    "                predicted = pred_prob.round()\n",
    "                #_, predicted = torch.max(outputs, 1)\n",
    "                resnet_predictions.extend(outputs.cpu().numpy())\n",
    "                y_pred.extend(predicted.cpu().numpy()) # bu benim ust mlp ye koyacagim input oluyor su an\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "            \n",
    "\n",
    "            # Convert lists to tensors for calculation\n",
    "            y_true_tensor = torch.tensor(y_true)\n",
    "            y_pred_tensor = torch.tensor(y_pred)\n",
    "            \n",
    "            # Calculating precision, recall, and F1 score using PyTorch\n",
    "            TP = ((y_pred_tensor == 1) & (y_true_tensor == 1)).sum().item()\n",
    "            FP = ((y_pred_tensor == 1) & (y_true_tensor == 0)).sum().item()\n",
    "            FN = ((y_pred_tensor == 0) & (y_true_tensor == 1)).sum().item()\n",
    "            TN = ((y_pred_tensor == 0) & (y_true_tensor == 0)).sum().item()\n",
    "\n",
    "            accuracy = (TP + FN) / (TP + FN + FP + TN)\n",
    "            precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "            recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            auc = np.round(roc_auc_score(y_true, y_pred), 3)\n",
    "\n",
    "            print(f'Accuracy: {accuracy}')\n",
    "            print(f'Precision: {precision}')\n",
    "            print(f'Recall: {recall}')\n",
    "            print(f'F1 Score: {f1}')\n",
    "            \n",
    "            wandb.log({\"precision\":precision})\n",
    "            wandb.log({\"recall\":recall})\n",
    "            wandb.log({\"f1 score\":f1})\n",
    "            wandb.log({\"AUC\":auc})\n",
    "\n",
    "\n",
    "\n",
    "class EnsembeModel(nn.Module): # This neural network merges the \n",
    "\n",
    "    def __init__(self,resnet_input,numerical_input):\n",
    "        super(EnsembeModel,self).__init__()\n",
    "        self.resnet_input = resnet_input\n",
    "        self.numerical_input = numerical_input\n",
    "        self.total_params = torch.add(self.resnet_input,self.numerical_input) \n",
    "        self.classifier = nn.Linear(32,1)\n",
    "\n",
    "    def forward(self,x1,x2):\n",
    "        x = self.classifier(F.sigmoid(self.total_params))\n",
    "        return x    \n",
    "    \n",
    "def train_ensemble_model(resnet_input,numerical_input):\n",
    "    # actual values bir yerde olmali \n",
    "    actual_output = torch.tensor(0,dtype = torch.float32)\n",
    "    ensemble_model = EnsembeModel(resnet_input,numerical_input)\n",
    "    prediction_prob = ensemble_model(ensemble_model.total_params)\n",
    "    prediction_label = prediction_prob.round()\n",
    "    loss_val = nn.BCELoss()(prediction_label,actual_output)\n",
    "    loss_val.backward()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid'\n",
    "    }\n",
    "\n",
    "metric = {\n",
    "    'name': 'loss',\n",
    "    'goal': 'minimize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "parameters_dict = {\n",
    "    'optimizer': {\n",
    "        'values': ['adam']\n",
    "        },\n",
    "    'learning_rate': {\n",
    "        \"values\" : [0.001] # 0.0001 vermeyi bi dene bakalim\n",
    "      },\n",
    "      'batch_size': {\n",
    "        \"values\" : [32]\n",
    "      },\n",
    "      \"epochs\" : {\n",
    "        \"values\" : [1]\n",
    "      }\n",
    "    }\n",
    " \n",
    "sweep_config['parameters'] = parameters_dict\n",
    "\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(sweep_config)\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"Pretrained Output\")\n",
    "\n",
    "wandb.agent(sweep_id, train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x00000290E4A628D0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 29249b5d190, raw_cell=\"numerical_predictions = []\n",
      "def pathology_encoder(v..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/ae423/OneDrive%20-%20University%20of%20Sussex/Desktop/AlphanElmasDissertation/Alphan_Elmas_Dissertation%20%281%29%20%281%29.ipynb#X33sZmlsZQ%3D%3D>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:441\u001b[0m, in \u001b[0;36m_WandbInit._resume_backend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    440\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\interface\\interface.py:732\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n\u001b[1;32m--> 732\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py:363\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[1;34m(self, resume)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    362\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[1;34m(self, record, local)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[0;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ae423\\AppData\\Local\\Temp\\ipykernel_27552\\1074460419.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_mass_df.rename(columns={\"breast_density\":\"breast density\"},inplace=True)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['pathology'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27552\\1074460419.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbc_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pathology\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbc_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pathology\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"breast density\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"left or right breast\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"calc type\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"calc distribution\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"pathology\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"mass shape\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"mass margins\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pathology\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pathology\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mNumericalClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5577\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m250.0\u001b[0m   \u001b[1;36m150.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5578\u001b[0m         \u001b[0mfalcon\u001b[0m  \u001b[0mspeed\u001b[0m   \u001b[1;36m320.0\u001b[0m   \u001b[1;36m250.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5580\u001b[0m         \"\"\"\n\u001b[1;32m-> 5581\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5584\u001b[0m             \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4784\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4786\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4787\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4788\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4790\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4791\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4855\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4856\u001b[0m                 \u001b[1;31m# Check if label doesn't exist along axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4857\u001b[0m                 \u001b[0mlabels_missing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4858\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raise\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlabels_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4859\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4862\u001b[0m                 \u001b[1;31m# GH#45860\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['pathology'] not found in axis\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x00000290E4A628D0>> (for post_run_cell), with arguments args (<ExecutionResult object at 290e50d3790, execution_count=23 error_before_exec=None error_in_exec=\"['pathology'] not found in axis\" info=<ExecutionInfo object at 29249b5d190, raw_cell=\"numerical_predictions = []\n",
      "def pathology_encoder(v..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/ae423/OneDrive%20-%20University%20of%20Sussex/Desktop/AlphanElmasDissertation/Alphan_Elmas_Dissertation%20%281%29%20%281%29.ipynb#X33sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:436\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    435\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m--> 436\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\interface\\interface.py:724\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    723\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[1;32m--> 724\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py:359\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[1;34m(self, pause)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[1;32m--> 359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[1;34m(self, record, local)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[0;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\AlphanElmas\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    }
   ],
   "source": [
    "numerical_predictions = []\n",
    "def pathology_encoder(val):\n",
    "    return \"MALIGNANT\" if val == \"MALIGNANT\" else \"NORMAL\"\n",
    "\n",
    "calc_df = pd.read_csv(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\calc_case_description_train_set.csv\")\n",
    "c_test = pd.read_csv(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\calc_case_description_test_set.csv\")\n",
    "calc_df[\"pathology\"] = calc_df[\"pathology\"].map(pathology_encoder)\n",
    "cols_to_be_used = [\"breast density\",\"left or right breast\",\"calc type\",\"calc distribution\",\"pathology\"]\n",
    "new_calc_df = calc_df[cols_to_be_used]\n",
    "\n",
    "mass_df = pd.read_csv(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\mass_case_description_train_set.csv\")\n",
    "m_test = pd.read_csv(\"C:\\\\Users\\\\ae423\\\\OneDrive - University of Sussex\\\\Desktop\\\\AlphanElmasDissertation\\\\csv\\\\mass_case_description_test_set.csv\")\n",
    "mass_df[\"pathology\"] = mass_df[\"pathology\"].map(pathology_encoder)\n",
    "cols_to_be_used = [\"breast_density\",\"left or right breast\",\"mass shape\",\"mass margins\",\"pathology\"]\n",
    "new_mass_df = mass_df[cols_to_be_used]\n",
    "new_mass_df.rename(columns={\"breast_density\":\"breast density\"},inplace=True)\n",
    "\n",
    "bc_df = pd.concat([new_calc_df,new_mass_df])\n",
    "lbl_encoder = LabelEncoder()\n",
    "bc_df['left or right breast'] = lbl_encoder.fit_transform(bc_df['left or right breast'])\n",
    "bc_df['calc type'] = lbl_encoder.fit_transform(bc_df['calc type'])\n",
    "bc_df[\"calc distribution\"] = lbl_encoder.fit_transform(bc_df['left or right breast'])\n",
    "bc_df['pathology'] = lbl_encoder.fit_transform(bc_df['pathology'])\n",
    "bc_df['mass shape'] = lbl_encoder.fit_transform(bc_df['mass shape'])\n",
    "bc_df['mass margins'] = lbl_encoder.fit_transform(bc_df['mass margins'])\n",
    "\n",
    "bc_df[\"breast density\"] = bc_df[\"breast density\"].astype(float)\n",
    "\n",
    "cols = [\"breast density\",'left or right breast', 'calc type','calc distribution', 'mass shape', 'mass margins']\n",
    "scaler = StandardScaler()\n",
    "bc_df[cols] = scaler.fit_transform(bc_df[cols])\n",
    "\n",
    "x_train,y_train = bc_df[\"pathology\"], bc_df[\"pathology\"]\n",
    "df = pd.concat([c_test,m_test])\n",
    "df = df[[\"breast density\",\"left or right breast\",\"calc type\",\"calc distribution\",\"pathology\",\"mass shape\",\"mass margins\"]] \n",
    "x_test,y_test = df.drop(\"pathology\"), df[\"pathology\"]\n",
    "\n",
    "class NumericalClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(6, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.linear_relu_stack(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "y_train = np.reshape(y_train,(y_train.shape[0],1))\n",
    "y_test = np.reshape(y_test,(y_test.shape[0],1))\n",
    "\n",
    "\n",
    "train_set = np.concatenate((x_train,y_train),axis=1)\n",
    "test_set = np.concatenate((x_test,y_test),axis=1)\n",
    "train_set = torch.tensor(train_set, dtype=torch.float32)\n",
    "test_set = torch.tensor(test_set, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def train_numerical_classifier():\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = DataLoader(test_set,  batch_size=batch_size, shuffle=False)\n",
    "    epochs = 10\n",
    "    optimizer = build_optimizer(NumericalClassifier(),\"adam\",learning_rate=0.001)\n",
    "    model = NumericalClassifier()\n",
    "    i = 0\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        for batch_num, input_data in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            x, y = input_data[:,:6], input_data[:,6]\n",
    "            output = model(x)\n",
    "            y = torch.reshape(y,(y.shape[0],1))\n",
    "            loss = nn.BCELoss()(output, y)\n",
    "            loss.backward()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_num % 32 == 0:\n",
    "                print('\\tEpoch %d | Batch %d | Loss %6.2f' % (epoch, batch_num, loss.item()))\n",
    "        print('Epoch %d | Loss %6.2f' % (epoch, sum(losses)/len(losses)))\n",
    "        \n",
    "        model.eval()\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        with torch.no_grad():\n",
    "            for values in test_loader:\n",
    "                labels = values[:,6] \n",
    "                outputs = model(values[:,:6])\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                numerical_predictions.extend(predicted.cpu().numpy())\n",
    "                y_pred.extend(predicted.cpu().numpy()) # buradaki deger de ayni sekilde bir sonraki mlp ye koyacagim ikinci input oluyor.\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "            # Convert lists to tensors for calculation\n",
    "            y_true_tensor = torch.tensor(y_true)\n",
    "            y_pred_tensor = torch.tensor(y_pred)\n",
    "\n",
    "\n",
    "            # Calculating precision, recall, and F1 score using PyTorch\n",
    "            TP = ((y_pred_tensor == 1) & (y_true_tensor == 1)).sum().item()\n",
    "            FP = ((y_pred_tensor == 1) & (y_true_tensor == 0)).sum().item()\n",
    "            FN = ((y_pred_tensor == 0) & (y_true_tensor == 1)).sum().item()\n",
    "\n",
    "            precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "            recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            auc = np.round(roc_auc_score(y_true, y_pred), 3)\n",
    "\n",
    "            print(f'Precision: {precision}')\n",
    "            print(f'Recall: {recall}')\n",
    "            print(f'F1 Score: {f1}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
